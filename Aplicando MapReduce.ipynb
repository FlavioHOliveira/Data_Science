{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP64GMLoywNjACNBFtzBWAz",
      "include_colab_link": false
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FlavioHOliveira/Data_Science/blob/master/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAzQFUlpyu59",
        "colab_type": "text"
      },
      "source": [
        "# **Usando MapReduce**\n",
        "\n",
        "A aplicação foi feita em modo pseudo distribuída (Em uma só maquína).\n",
        "\n",
        "*   Dados da VM (Virtual box 6.1).\n",
        "*   SO: CentOS 7.6\n",
        "*   Java version \"1.8.0_212\"\n",
        "*   Hadoop-3.2.0\n",
        "*   Zookeeper-3.5.5\n",
        "*   8GB memory - GPU 4 cores.\n",
        "\n",
        "\n",
        "#### **Armazenando o dataset no HDFS.**\n",
        "\n",
        "Para que o processamento seja feito, os dados precisam estar dentro do HDFS.\n",
        "\n",
        "Fonte: https://grouplens.org/datasets/movielens/100k/\n",
        "\n",
        
        "<img src=\"https://i.imgur.com/Mq0Jbve.png\" width=\"60%\">\n",
        "\n",
        "**Últimas linhas do dataset.**\n",
        "\n",
        "As colunas respectivamente são: ID do usuário, ID do filme, avaliação e data da avaliação.\n",
        "\n",
        "<img src=\"https://i.imgur.com/Amah3a3.png\" width=\"60%\">\n",
        "\n",
        "**Código para avaliação de filmes.**\n",
        "\n",
        "A contagem de cada rating e a ocorrência é armazenada.\n",
        "Após o mapeando, as informações de cada rating juntamente com a frequência acumulada de cada ocorrência é gerada no resultado. \n",
        "\n",
        "\n",
        "<img src=\"https://i.imgur.com/M7OWWDL.png\" width=\"60%\">\n",
        "\n",
        "**Executando o processo em um cluster hadoop.**\n",
        "\n",
        "\n",
        "<img src=\"https://i.imgur.com/MIapR46.png\" width=\"60%\">\n",
        "\n",
        "\n",
        "**Processo de Mapeamento e Redução.**\n",
        "\n",
        "\n",
        "<img src=\"https://i.imgur.com/cgzloCO.png\" width=\"60%\">\n",
        "\n",
        "\n",
        "<img src=\"https://i.imgur.com/R4zs51x.png\" width=\"60%\">\n",
        "\n",
        "\n",
        "\n",
        "# **Data Mining em dados não estruturados**\n",
        "\n",
        "O objetivo da mineração é buscar dentro do dataset, as palavras que mais se repetem.\n",
        "\n",
        "Fonte do dataset: https://www.gutenberg.org/ebooks/1342.\n",
        "\n",
        "Será desconsiderado qualquer outro tipo de carácter que não seja palavras.\n",
        "\n",
        "\n",
        "**Armazenando o dados dentro do HDFS.**\n",
        "\n",
        "\n",
        "<img src=\"https://i.imgur.com/yQL2erd.png\" width=\"60%\">\n",
        "\n",
        "**Visualizando as últimas linhas do dataset.**\n",
        "\n",
        "\n",
        "<img src=\"https://uploaddeimagens.com.br/images/002/640/325/original/dataset2.png?1589038010\" width=\"60%\">\n",
        "\n",
        "\n",
        "**Código utilizado no processo.**\n",
        "\n",
        "Foi usado o pacote **MRjob** para a conversão em Java, expressões regulares para a filtragem das palavras, e dois jobs foram aninhados para que o processo de mapeamento e redução fossem realizados.\n",
        "\n",
        "\n",
        "<img src=\"https://i.imgur.com/6Pog7em.png\" width=\"60%\">\n",
        "\n",
        "\n",
        "**Execução da aplicação python em um cluster hadoop.**\n",
        "\n",
        "\n",
        "<img src=\"https://i.imgur.com/c3b5JLL.png\" width=\"60%\">\n",
        "\n",
        "**Processo de Mapeamento e Redução.**\n",
        "\n",
        "Inicialmente houve um erro na execução, porem após a criação do arquivo conf. do MRjob, o problema foi sanado.\n",
        "\n",
        "\n",
        "<img src=\"https://i.imgur.com/wPCLFrm.png\" width=\"60%\">\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"https://i.imgur.com/R05uMkU.png\" width=\"60%\">\n",
        "\n",
        "\n",
        "<img src=\"https://i.imgur.com/J65iZcA.png\" width=\"60%\">\n",
        "\n",
        "\n",
        "<img src=\"https://i.imgur.com/k3r5HOo.png\" width=\"60%\">\n",
        "\n",
        "\n",
        "<img src=\"https://i.imgur.com/BITd0Ha.png\" width=\"60%\">\n",
        "\n",
        "A quantidade de palavras foi ordernada para melhorar a obtenção dos resultados, com isso facilitou a visualização das palavras que menos e mais se repetem no dataset.\n",
        "\n"
      ]
    }
  ]
}
